---
title: "Comparison between did and didwrappers"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Comparison between did and didwrappers}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette compares the `did` and the current package using the example data in the `did` package, `mpdta`.

The example dataset that is used here contain county-level teen employment (`lemp`) for years 2003-2007. The treatment is minimum wage. The `first.treat` variable in the data encodes the year the county raised minimum wage over the federally-mandated level. 

This vignette should be read along with the linked [article](https://bcallaway11.github.io/did/) by Brantly Callaway. I recreate the main results that were produced by the `did` package, and then follow up with the comparable results of `didwrappers`. The differences between the packages will become clear soon.  


```{r setup}
library(didwrappers)
library(did)
data(mpdta)
```

The first step in the `did` algorithm is to produce the group-time component differences-in-differences estimates. I also time the run times.

```{r}
startt = Sys.time()
out <- did::att_gt(yname = "lemp",
              gname = "first.treat",
              idname = "countyreal",
              tname = "year",
              xformla = ~1,
              data = mpdta,
              est_method = "reg"
              )
endt = Sys.time()
print(paste("Time elapsed:",endt-startt,"seconds"))
```

The `didwrappers` package produces a similar object but at the more granular unit-time level.
This takes longer to run. The syntax remains the same, only the function name should need to change. 

```{r}
startt = Sys.time()
out_it <- didwrappers::att_it(yname = "lemp",
              gname = "first.treat",
              idname = "countyreal",
              tname = "year",
              xformla = ~1,
              data = mpdta,
              est_method = "reg"
              )
endt = Sys.time()
print(paste("Time elapsed:",endt-startt,"seconds"))
```

It takes quite a bit longer to do things at the county level than at the group level, which is the year that minimum wage is raised. There are certain advantages to having the more disaggregate county-level object that `didwrappers:att_it` produces, particularly, if aggregation across other attributes are needed. 

The `didwrappers` package has a function to view this data as a data frame. It is similar to `summary` functionality in `did`, but handier if you wish to export the object as a data-frame than a list. Here are the first 5 records of the table.

```{r}
didwrappers::attit_table(out_it)[1:5,1:5]
```

Now these can be aggregated at the group level, dynamic level, calendar-time level. Starting with the object produced by the call to the `did:att_gt` function, let's take the group average. 

```{r}
group_effects <- did::aggte(out, type = "group")
```

The `didwrappers` package has a handy function to view these as a data frame.

```{r}
didwrappers::aggite_table(group_effects)
```

Now, to trying this with the unit-time object. The syntax is quite similar, and these aggregation functions are not so computationally expensive to run, even with a larger object. 

```{r}
group_effects_it <- didwrappers::aggite(out_it, type = "group")
didwrappers::aggite_table(group_effects_it)
```

The estimates produced by these packages are the same. The differences are in the standard errors. The standard errors are smaller under the latter which uses a bootstrap in the second stage. This isn't always the case, however. 

One more aggregation method before the end of this vignette. Going back to the group-time object, 

```{r}
es <- did::aggte(out, type = "dynamic")
didwrappers::aggite_table(es)
```

With the unit-time level algorithm,

```{r}
es_it <- didwrappers::aggite(out_it, type = "dynamic")
didwrappers::aggite_table(es_it)
```

Again the differences are in the standard errors, which are smaller under the latter algorithm. But the substantive results are the same. 

Let's now look at the overall post-treatment effect. Different aggregations give different effects. Starting with the outputs of `did`,

```{r}
paste("Overall effect from group aggregation is",round(group_effects$overall.att,3))
paste("Overall effect from dynamic aggregation is",round(es$overall.att,3))
```

For the outputs of `didwrappers`,

```{r}
paste("Overall effect from group aggregation is", round(group_effects_it$overall.att,3))
paste("Overall effect from dynamic aggregation is",round(es_it$overall.att,3))
```

They are not the same, but are the same sign. The differences are in the weighting, which is slightly different across the two algorithms and even across the aggregation schemes.  

For 95\% confidence intervals, starting with the `did` objects:

```{r}
paste("CI for overall effect from group aggregation is","[",round(group_effects$overall.att-1.96*group_effects$overall.se,3),",",round(group_effects$overall.att+1.96*group_effects$overall.se,3),"]")
paste("CI for overall effect from dynamic aggregation is","[",round(es$overall.att-1.96*group_effects$overall.se,3),",",round(es$overall.att+1.96*group_effects$overall.se,3),"]")
```

Using the `didwrappers` object,

```{r}
paste("CI for overall effect from group aggregation is","[",round(group_effects_it$overall.lci,3),",",round(group_effects_it$overall.uci,3),"]")
paste("CI for overall effect from dynamic aggregation is","[",round(es_it$overall.lci,3),",",round(es_it$overall.uci,3),"]")
```

The overall dynamic effects are not significant under the latter algorithm, despite all of the component dynamic effects being so. 


The results presented were for an unconditional differences-in-difference. But unconditional results might be misleading, because the treatment and control groups are too different. In such cases, re-weighting the control units so that they look similar is one way to proceed. This is the snippet that would implement a weighting algorithm in the `did` package.

```{r}
out_lpop <- did::att_gt(yname = "lemp",
              gname = "first.treat",
              idname = "countyreal",
              tname = "year",
              xformla = ~lpop,
              data = mpdta,
              est_method = "ipw"
              )
```

The call in the `didwrappers` package is similar, but I am going to suppress warnings because I expect some overlap violations.

```{r, message=FALSE, warning=FALSE}
out_it_lpop <- didwrappers::att_it(yname = "lemp",
              gname = "first.treat",
              idname = "countyreal",
              tname = "year",
              xformla = ~lpop,
              data = mpdta,
              est_method = "ipw"
              )
```

Even when the group-level algorithm doesn't have overlap violations, the unit-level algorithm does. The default setting is to remove the violating units, but this can be changed by setting `overlap = "retain"` in the initial `att_it` call. The unit that the overlap violation occurred at has the lowest population of all the counties in the sample. For such a violation to occur at the group level, the counties treated at a time must have a lower average population than all the untreated counties. 

Whether aggregation should be at the group-level or the unit-level should come down to the nature of the data. For example, if there are many similar units, a group level algorithm is ideal for its speed and statistical properties. If there are a few heterogeneous units, and only few will have good comparisons, then a unit-level algorithm may do better. Analysts may use the unit-level algorithm as a complement to diagnose outliers that are obscured by a group-level algorithm. 


