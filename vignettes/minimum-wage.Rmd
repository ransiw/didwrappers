---
title: "Minimum wage example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Minimum wage example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette goes through some of the main functions of the `didwrappers` package using the example data in the `did` package. Another vignette compares these two packages for the same data. Use `browseVignettes("didwrappers")` to access that, and other vignettes. I also recommend Brantly Callaway's [article](https://bcallaway11.github.io/did/).  

```{r setup}
library(didwrappers)
data(mpdta)
```

The data consists of the minimal number of elements required for the algorithm. The outcome variable of log of teen employment `lemp`, the time (numeric) that the county first raised minimum wage `first.treat`, the numeric identifier for the county or unit `countyreal`, and the `year`. 

```{r}
mpdta[1:4,]
```

The first step is to calculate every unit-time difference-in-difference object. This code snippet does that.

```{r}
out_it <- didwrappers::att_it(yname = "lemp",
              gname = "first.treat",
              idname = "countyreal",
              tname = "year",
              data = mpdta
              )
```

Then these could be aggregated to give an overall post-treatment effect. A simple aggregation could be done as follows,

```{r}
simple = didwrappers::aggite(out_it, type="simple")
simple$overall.att
simple$overall.se
simple$overall.lci
simple$overall.uci
```

But there is more that can be done. Perhaps, we want to see the effect of raising minimum wage for all counties that raised the minimum wage in 2004, or 2007. 

```{r}
group = didwrappers::aggite(out_it, type="group")
```

A further function can be useful to unravel the list object into a data-frame.

```{r}
didwrappers::aggite_table(group)
```

This shows that on average counties that raised minimum wage in 2004, and 2006 saw a statistically significant (at 95\%) drop in teen employment. For 2007, the effect was negative, but not statistically significant. 

One concern with this type of aggregation is that the counties that raised minimum wage in 2004 have more post-treatment observations than counties that raise minimum wage later. If raising the minimum wage has different dynamic effects, we want to be able to see that. To do that, we could cut the unit-time object `out_it` a different way: at the dynamic level. 


```{r}
dynamic = didwrappers::aggite(out_it, type="dynamic")
didwrappers::aggite_table(dynamic)
```

It also gives us placebo trends. All post-treatment effects are negative. But, the immediate placebo effect is also negative, which says that the counties that raised their minimum wage was already seeing a drop in teen employment. This does not necessarily imply that we should discard the post-treatment effects as reflecting a negative teen employment trend that began before the minimum wage law. Yet, it requires caution and further investigation. 

We may consider weighting the estimates by population of the county,

```{r}
out_it_weight <- didwrappers::att_it(yname = "lemp",
              gname = "first.treat",
              idname = "countyreal",
              tname = "year",
              data = mpdta,
              weightsname = "lpop",
              weightfs = TRUE
              )
dynamic_weight = didwrappers::aggite(out_it_weight, type="dynamic")
didwrappers::aggite_table(dynamic_weight)
```
When weighted by population, all placebo tests are insignificant, but so is the immediate post-treatment effect. All other post-treatment effects are significantly different from zero. 

We can also retrieve the overall effect from these same objects.

```{r}
dynamic$overall.att
dynamic_weight$overall.att
```


Until now we have run unconditional differences-in-differences. But, it might not be appropriate to compare counties of very different population. There are a variety of reweighting algorithms (same as those in the `did` package) that can help. I'll demonstrate with inverse-propensity score weighting. I suppress the warning messages that come when the overlap condition is violated, but we'll quickly see how to figure out the ones that are the problem. 

```{r, message=FALSE, warning=FALSE}
out_it_lpop <- didwrappers::att_it(yname = "lemp",
              gname = "first.treat",
              idname = "countyreal",
              tname = "year",
              xformla = ~lpop,
              data = mpdta,
              est_method = "ipw"
              )
```

Save this into a table, and look at the units for which the overlap condition failed. 

```{r}
out_it_lpop_tbl <- didwrappers::attit_table(out_it_lpop)
out_it_lpop_tbl[is.na(out_it_lpop_tbl$se),c(1:6,8,9)]
```

For one of the counties, overlap failed. As shown by the `ipwqual` field, the maximum propensity score being that close to 1 shows that almost all the weight lands on just one control unit. This can make standard errors inflate. If you want to see what would happen anyway set the option `overlap="retain"` in the initial `att_it` call. 

The rest of the steps can continue as above. For a quick comparison to the dynamic effects, run the following snippet. Because the overlap problems create issues for the standard errors, we should drop these. 

```{r}
dynamic_lpop = didwrappers::aggite(out_it_lpop, type="dynamic", na.rm = TRUE)
didwrappers::aggite_table(dynamic_lpop)
```

The estimates are a little different from the unconditional version. But the substantive conclusions made would remain the same. The placebo tests are all insignificant.

Another option with the `didwrappers` package is that you can also choose an aggregation level based on a different variable. I'll create such a variable out of the `lpop` variable. 

```{r}
mpdta$lpop2 = round(mpdta$lpop)
table(mpdta[mpdta$first.treat>0,"lpop2"])
```

There are 8 population categories in the treatment set, but the category 0, 1, and 7 have 3 or less units. 

We may want to compare counties of similar population to each other. Weighting was one way to do that, but another is to do compared within the population category of population size. The `cohort` feature is the one to do that. 


```{r, message=FALSE}
out_it_cohort <- didwrappers::att_it(yname = "lemp",
              gname = "first.treat",
              idname = "countyreal",
              tname = "year",
              cohort = "lpop2",
              customnames = "lpop2",
              data = mpdta
              )
```

Aggregating by population level,

```{r}
cohort = didwrappers::aggite(out_it_cohort, type="lpop2", na.rm = TRUE)
didwrappers::aggite_table(cohort)
```

The effect is positive for the populations in bucket 0, 1, and 7, but these are also the same ones that we didn't have enough treatment units of. So, they may not be representative of those population levels. 

But even with 11 treatment units, the effect for population bucket 6 is very close to zero. In this sample, minimum wage increases affects the mid-population counties more than the high population counties. 
